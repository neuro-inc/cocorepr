{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop tree representation\n",
    "> Methods to work with `crop_tree` representation: load/dump from/to a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp crop_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import json\n",
    "import shutil\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass, Field\n",
    "from typing import *\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool, Lock\n",
    "\n",
    "from cocorepr.utils import sort_dict, measure_time, read_image, write_image, cut_bbox\n",
    "from cocorepr.coco import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def load_crop_tree(\n",
    "    source_dir: Union[str, Path],\n",
    "    base_coco: CocoDataset,\n",
    "    *,\n",
    "    kind: str = \"object_detection\",\n",
    ") -> CocoDataset:\n",
    "    \"\"\" Load modified set of crops from `{path}/crops` and use it\n",
    "        to filter out the annotations in `base_coco`.\n",
    "    \"\"\"\n",
    "    dataset_class = get_dataset_class(kind)\n",
    "\n",
    "    source_dir = Path(source_dir)\n",
    "    logger.info(f\"Loading crop_tree from dir: {source_dir}\")\n",
    "    if not source_dir.is_dir():\n",
    "        raise ValueError(f\"Source dir not found: {source_dir}\")\n",
    "\n",
    "    crops_dir = source_dir / 'crops'\n",
    "    if not crops_dir.exists():\n",
    "        raise ValueError(f'Source crops dir not found: {crops_dir}')\n",
    "\n",
    "    catid2cat = {cat.id: cat for cat in base_coco.categories}\n",
    "    imgid2img = {img.id: img for img in base_coco.images}\n",
    "    annid2ann = {ann.id: ann for ann in base_coco.annotations}\n",
    "    annid2imgid = {ann.id: ann.image_id for ann in base_coco.annotations}\n",
    "\n",
    "    res_cats = {}\n",
    "    res_imgs = {}\n",
    "    res_anns = {}\n",
    "\n",
    "    with measure_time() as timer1:\n",
    "        for count1, ann_dir in enumerate(crops_dir.iterdir(), 1):\n",
    "            cat_id = int(ann_dir.name.split('--')[-1])\n",
    "            cat = catid2cat[cat_id]\n",
    "\n",
    "            with measure_time() as timer2:\n",
    "                for count2, ann_file in enumerate(ann_dir.glob('*.png'), 1):\n",
    "                    ann_id = int(ann_file.stem)\n",
    "                    ann = annid2ann[ann_id]\n",
    "                    img_id = annid2imgid[ann_id]\n",
    "                    img = imgid2img[img_id]\n",
    "\n",
    "                    res_cats[cat.id] = cat\n",
    "                    res_imgs[img.id] = img\n",
    "                    res_anns[ann.id] = ann\n",
    "            logger.info(f'  loaded {count2} crops from {ann_dir}: elapsed {timer2.elapsed}')\n",
    "        logger.info(f'Loaded from {count1} crop directories: elapsed {timer1.elapsed}')\n",
    "\n",
    "    with measure_time() as timer:\n",
    "        D = {\n",
    "            **base_coco.to_dict(),\n",
    "            'images': list(res_imgs.values()),\n",
    "            'annotations': list(res_anns.values()),\n",
    "            'categories': list(res_cats.values()),\n",
    "        }\n",
    "    logger.info(f'Dataset dict constructed: elapsed {timer.elapsed}')\n",
    "    \n",
    "    with measure_time() as timer:\n",
    "        coco = dataset_class.from_dict(D)\n",
    "    logger.info(f'Dataset object constructed: elapsed {timer.elapsed}: {coco.to_full_str()}')\n",
    "    \n",
    "    return coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[124710, 124713, 131774, 131812, 183020, 183030]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading json_tree from dir: ../examples/coco_chunk/json_tree\n",
      "DEBUG:root:Loaded 6 json chunks from ../examples/coco_chunk/json_tree/images\n",
      "DEBUG:root:Loaded 8 json chunks from ../examples/coco_chunk/json_tree/licenses\n",
      "DEBUG:root:Loaded 6 json chunks from ../examples/coco_chunk/json_tree/annotations\n",
      "DEBUG:root:Loaded 3 json chunks from ../examples/coco_chunk/json_tree/categories\n",
      "DEBUG:root:Loaded single-file json chunk ../examples/coco_chunk/json_tree/info.json\n",
      "INFO:root:  json files loaded: elapsed 0:00:00.006241\n",
      "INFO:root:  dataset constructed: elapsed 0:00:00.004604\n",
      "INFO:root:Loaded from json_tree: CocoObjectDetectionDataset(images=6, licenses=8, annotations=6, categories=3)\n",
      "INFO:root:Loading crop_tree from dir: ../examples/coco_chunk/crop_tree\n",
      "INFO:root:  loaded 2 crops from ../examples/coco_chunk/crop_tree/crops/bicycle--2: elapsed 0:00:00.000189\n",
      "INFO:root:  loaded 2 crops from ../examples/coco_chunk/crop_tree/crops/person--1: elapsed 0:00:00.000154\n",
      "INFO:root:  loaded 2 crops from ../examples/coco_chunk/crop_tree/crops/car--3: elapsed 0:00:00.000172\n",
      "INFO:root:Loaded from 3 crop directories: elapsed None\n",
      "INFO:root:Dataset dict constructed: elapsed 0:00:00.001310\n",
      "INFO:root:Dataset object constructed: elapsed 0:00:00.001011: CocoObjectDetectionDataset(images=6, licenses=8, annotations=6, categories=3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[124710, 124713, 131774, 131812, 183020, 183030]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "import tempfile\n",
    "from cocorepr.json_tree import load_json_tree, dump_json_tree\n",
    "from pathlib import Path\n",
    "\n",
    "SRC_COCO = '../examples/coco_chunk/json_tree/'\n",
    "SRC_BLOB = '../examples/coco_chunk/crop_tree/'\n",
    "\n",
    "expected_crop_ids = sorted([int(p.stem)\n",
    "                            for cat_p in (Path(SRC_BLOB)/'crops').iterdir()\n",
    "                            for p in cat_p.iterdir()])\n",
    "display(expected_crop_ids)\n",
    "\n",
    "DST = tempfile.mktemp()\n",
    "d = load_crop_tree(SRC_BLOB, load_json_tree(SRC_COCO))\n",
    "\n",
    "actual_crop_ids = sorted([ann.id for ann in d.annotations])\n",
    "display(actual_crop_ids)\n",
    "assert actual_crop_ids == expected_crop_ids, actual_crop_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _cut_to_chunks(L: List[Any], n) -> List[List[Any]]:\n",
    "    assert n > 0\n",
    "    return [\n",
    "        L[i: i+n] + [None]*(n - len(L[i: i+n]))\n",
    "        for i in range(0, len(L), n)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = _cut_to_chunks([1,2,3,4,5,6,7], 4)\n",
    "assert res == [[1, 2, 3, 4], [5, 6, 7, None]]\n",
    "\n",
    "res = _cut_to_chunks([1,2,3,4,5,6,7], 3)\n",
    "assert res == [[1, 2, 3], [4, 5, 6], [7, None, None]], res\n",
    "\n",
    "res = _cut_to_chunks([1,2,3,4,5,6,7], 2)\n",
    "assert res == [[1, 2], [3, 4], [5, 6], [7, None]], res\n",
    "\n",
    "res = _cut_to_chunks([1,2,3,4,5,6,7], 1)\n",
    "assert res == [[1], [2], [3], [4], [5], [6], [7]], res\n",
    "\n",
    "res = _cut_to_chunks([], 2)\n",
    "assert res == []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def _process_image(img, anns, images_dir, crops_dir, catid2cat, anns_failed_file):\n",
    "    file_name = img.get_file_name()\n",
    "    image_file = images_dir / file_name\n",
    "    image = None\n",
    "\n",
    "    for ann in anns:\n",
    "        cat = catid2cat[ann.category_id]\n",
    "        cat_dir = crops_dir / cat.get_dir_name()\n",
    "        cat_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        ann_file = cat_dir / ann.get_file_name()\n",
    "        if ann_file.is_file():\n",
    "            continue\n",
    "        f\n",
    "        image = image or read_image(image_file, download_url=img.coco_url)\n",
    "        box = cut_bbox(image, ann.bbox)\n",
    "        try:\n",
    "            write_image(box, ann_file)\n",
    "        except ValueError as e:\n",
    "            logger.error(e)\n",
    "            with anns_failed_file.open('a') as f:\n",
    "                f.write(json.dumps(ann.to_dict(), ensure_ascii=False) + '\\n')\n",
    "\n",
    "\n",
    "def _process_image_list(l):\n",
    "    l = l or []\n",
    "    for (img, anns, images_dir, crops_dir, catid2cat, anns_failed_file) in l:\n",
    "        _process_image(img, anns, images_dir, crops_dir, catid2cat, anns_failed_file)\n",
    "\n",
    "\n",
    "def dump_crop_tree(\n",
    "    coco: CocoDataset,\n",
    "    target_dir: Union[str, Path],\n",
    "    *,\n",
    "    kind: str = 'object_detection',\n",
    "    skip_nulls: bool = True,\n",
    "    overwrite: bool = False,\n",
    "    indent: Optional[int] = 4,\n",
    "    num_processes: int = 1,\n",
    ") -> None:\n",
    "    try:\n",
    "        from tqdm.auto import tqdm\n",
    "    except ImportError:\n",
    "        logger.warning(\"Could not import tqdm, please run 'pip install tqdm'\")\n",
    "        def tqdm(it, *args, **kwargs):\n",
    "            yield from it\n",
    "\n",
    "    dataset_class = get_dataset_class(kind)\n",
    "    if skip_nulls:\n",
    "        to_dict_function = dataset_class.to_dict_skip_nulls\n",
    "    else:\n",
    "        to_dict_function = dataset_class.to_dict\n",
    "\n",
    "    target_dir = Path(target_dir)\n",
    "    logger.info(f\"Dumping crop_tree to dir: {target_dir}\")\n",
    "\n",
    "    if overwrite:\n",
    "        if target_dir.is_dir():\n",
    "            logger.warning(f'Destination and will be overwritten: {target_dir}')\n",
    "    elif target_dir.is_dir():\n",
    "        raise ValueError(f\"Destination json tree dir already exists: {target_dir}\")\n",
    "\n",
    "    #if overwrite and target_dir.is_dir():\n",
    "    #    logger.info(f'Deleting old target directory {target_dir}')\n",
    "    #    shutil.rmtree(str(target_dir))\n",
    "\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "    catid2cat = {cat.id: cat for cat in coco.categories}\n",
    "\n",
    "    imgid2img = {img.id: img for img in coco.images}\n",
    "    imgid2anns = defaultdict(list)\n",
    "    for ann in coco.annotations:\n",
    "        imgid2anns[ann.image_id].append(ann)\n",
    "\n",
    "    images_dir = target_dir / 'images'\n",
    "    images_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    crops_dir = target_dir / 'crops'\n",
    "    crops_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    anns_failed = []\n",
    "    anns_failed_file = crops_dir / 'crops_failed.ndjson'\n",
    "    \n",
    "    if overwrite and crops_dir.is_dir():\n",
    "        logger.info(f'Cleaning extra files in root {target_dir}')\n",
    "        to_remove = []\n",
    "        \n",
    "        a = {images_dir}\n",
    "        b = {images_dir/img.get_file_name() for img in coco.images}\n",
    "        c = {crops_dir}\n",
    "        d = {crops_dir/catid2cat[cat.id].get_dir_name() for cat in coco.categories}\n",
    "        e = {crops_dir/catid2cat[ann.category_id].get_dir_name()/ann.get_file_name() for ann in coco.annotations}\n",
    "        all_files = a | b | c | d | e\n",
    "        \n",
    "        for p in target_dir.glob('**/*'):\n",
    "            if p not in all_files:\n",
    "                to_remove.append(p)\n",
    "        to_remove = sorted(to_remove)\n",
    "        removed_str = '\\n'.join(map(str, to_remove))\n",
    "        logger.info(f'Removing {len(to_remove)} files and dirs:\\n{removed_str}')\n",
    "        for p in to_remove:\n",
    "            if p.is_dir():\n",
    "                shutil.rmtree(str(p))\n",
    "            else:\n",
    "                p.unlink()\n",
    "        logger.info(f'Removed {len(to_remove)} files and dirs.')\n",
    "    \n",
    "    with measure_time() as timer:\n",
    "        pairs = [\n",
    "            (imgid2img[imgid], anns, images_dir, crops_dir, catid2cat, anns_failed_file)\n",
    "            for (imgid, anns) in imgid2anns.items()\n",
    "        ]\n",
    "        chunks = _cut_to_chunks(pairs, num_processes)\n",
    "        with Pool(num_processes) as pool:\n",
    "            result = list(tqdm(pool.imap(_process_image_list, chunks), total=len(imgid2anns), desc='Processing images'))\n",
    "        #process_map(_process_image_list, chunks, total=len(imgid2anns), desc='Processing images', max_workers=num_processes)\n",
    "            \n",
    "    logger.info(f'Crops written to {crops_dir}: elapsed {timer.elapsed}')\n",
    "    \n",
    "    if anns_failed:\n",
    "        logger.warning(f'Failed to process {len(anns_failed)} crops, see file {anns_failed_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading json_tree from dir: ../examples/coco_chunk/json_tree\n",
      "DEBUG:root:Loaded 6 json chunks from ../examples/coco_chunk/json_tree/annotations\n",
      "DEBUG:root:Loaded 3 json chunks from ../examples/coco_chunk/json_tree/categories\n",
      "DEBUG:root:Loaded 6 json chunks from ../examples/coco_chunk/json_tree/images\n",
      "DEBUG:root:Loaded 8 json chunks from ../examples/coco_chunk/json_tree/licenses\n",
      "DEBUG:root:Loaded single-file json chunk ../examples/coco_chunk/json_tree/info.json\n",
      "INFO:root:  json files loaded: elapsed 0:00:00.006863\n",
      "INFO:root:  dataset constructed: elapsed 0:00:00.004718\n",
      "INFO:root:Loaded from json_tree: CocoObjectDetectionDataset(annotations=6, categories=3, images=6, licenses=8)\n",
      "INFO:root:Dumping crop_tree to dir: /tmp/tmpev9dj44d\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daae29e676ed4cf282f6e787f3aa469a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing images:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Lock objects should only be shared between processes through inheritance",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-c834715763e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_json_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSRC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdump_crop_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_processes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mactual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetoutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' ls {DST}/crops'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-89-68930422534f>\u001b[0m in \u001b[0;36mdump_crop_tree\u001b[0;34m(coco, target_dir, kind, skip_nulls, overwrite, indent, num_processes)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_cut_to_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_processes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_processes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_process_image_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgid2anns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Processing images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;31m#process_map(_process_image_list, chunks, total=len(imgid2anns), desc='Processing images', max_workers=num_processes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0m__next__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m                    \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_handle_tasks\u001b[0;34m(taskqueue, put, outqueue, pool, cache)\u001b[0m\n\u001b[1;32m    429\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m                         \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m                         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_writable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/lib/python3.7/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(cls, obj, protocol)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/lib/python3.7/multiprocessing/synchronize.py\u001b[0m in \u001b[0;36m__getstate__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_spawning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0msl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_semlock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'win32'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/lib/python3.7/multiprocessing/context.py\u001b[0m in \u001b[0;36massert_spawning\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    354\u001b[0m         raise RuntimeError(\n\u001b[1;32m    355\u001b[0m             \u001b[0;34m'%s objects should only be shared between processes'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m             \u001b[0;34m' through inheritance'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m             )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Lock objects should only be shared between processes through inheritance"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "import tempfile\n",
    "from cocorepr.json_tree import load_json_tree\n",
    "\n",
    "SRC = '../examples/coco_chunk/json_tree/'\n",
    "DST = tempfile.mktemp()\n",
    "d = load_json_tree(SRC)\n",
    "\n",
    "dump_crop_tree(d, DST, num_processes=2)\n",
    "\n",
    "actual = ! ls {DST}/crops\n",
    "actual = set(actual)\n",
    "expected = set(c.get_dir_name() for c in d.categories)\n",
    "assert expected == actual, (expected, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
