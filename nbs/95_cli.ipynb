{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLI options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "from cocorepr.utils import log_elapsed_time\n",
    "from cocorepr.coco import merge_datasets, cut_annotations_per_category, remove_invalid_elements\n",
    "from cocorepr.json_file import *\n",
    "from cocorepr.json_tree import *\n",
    "from cocorepr.crop_tree import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def get_parser():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Tool for converting datasets in COCO format between different representations\"\n",
    "    )\n",
    "    parser.add_argument(\"--in_json_file\", type=Path, nargs=\"*\", default=[],\n",
    "                        help=(\n",
    "                            \"Path to one or multiple json files storing COCO dataset \"\n",
    "                            \"in `json_file` representation (all json-based datasets will be merged).\"\n",
    "                        ))\n",
    "\n",
    "    parser.add_argument(\"--in_json_tree\", type=Path, nargs=\"*\", default=[],\n",
    "                        help=(\n",
    "                            \"Path to one or multiple directories storing COCO dataset \"\n",
    "                            \"in `json_tree` representation (all json-based datasets will be merged).\"\n",
    "                        ))\n",
    "\n",
    "    parser.add_argument(\"--in_crop_tree\", type=Path, nargs=\"*\", default=[],\n",
    "                        help=(\n",
    "                            \"Path to one or multiple directories storing COCO dataset \"\n",
    "                            \"in `crop_tree` representation (all crop-based datasets will be merged and will \"\n",
    "                            \"overwrite the json-based datasets).\"\n",
    "                       ))\n",
    "\n",
    "    parser.add_argument(\"--out_path\", type=Path,\n",
    "                        help=\"Path to the output dataset (file or directory: depends on `--out_format`)\")\n",
    "\n",
    "    parser.add_argument(\"--out_format\", choices=['json_file', 'json_tree', 'crop_tree'])\n",
    "\n",
    "    parser.add_argument(\"--seed\", type=int, default=42, help=\"Random seed.\")\n",
    "\n",
    "    parser.add_argument(\"--max_crops_per_class\", type=int, default=None,\n",
    "                        help=(\n",
    "                            \"If set, the tool will randomly select up to this number of \"\n",
    "                            \"crops (annotations) per each class (category) and drop the others.\"),\n",
    "                       )\n",
    "\n",
    "    parser.add_argument(\"--drop_invalid_elements\", action='store_true',\n",
    "                        help=\"If set, drops broken elements (for example, negative IDs or broken bboxes).\")\n",
    "\n",
    "    parser.add_argument(\"--dump_crop_tree_num_processes\", type=int, default=1)\n",
    "\n",
    "    parser.add_argument(\"--overwrite\", action='store_true',\n",
    "                        help=\"If set, will delete the output file/directory before dumping the result dataset.\")\n",
    "    parser.add_argument(\"--indent\", default=4,\n",
    "                        type=lambda x: int(x) if str(x).lower() not in ('none', 'null', '~') else None,\n",
    "                        help=\"Indentation in the output json files.\")\n",
    "\n",
    "    parser.add_argument(\"--debug\", action='store_true')\n",
    "\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "@log_elapsed_time(lambda t: logger.info(f'Total elapsed: {t.elapsed}'))\n",
    "def main(args=None):\n",
    "    args = args or get_parser().parse_args()\n",
    "\n",
    "    if args.debug:\n",
    "        logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "    logger.info(f'Arguments: {args}')\n",
    "\n",
    "    in_json_tree_list = args.in_json_tree\n",
    "    in_json_file_list = args.in_json_file\n",
    "    in_crop_tree_list = args.in_crop_tree\n",
    "\n",
    "    seed = args.seed\n",
    "    max_crops_per_class = args.max_crops_per_class\n",
    "    drop_invalid_elements = args.drop_invalid_elements\n",
    "\n",
    "    out_path = args.out_path\n",
    "    out_format = args.out_format\n",
    "    dump_crop_tree_num_processes = args.dump_crop_tree_num_processes\n",
    "    overwrite = args.overwrite\n",
    "    indent = args.indent\n",
    "\n",
    "    if out_path and not out_format or not out_path and out_format:\n",
    "        raise ValueError(f'Option --out_format requires --out_path and vice versa')\n",
    "\n",
    "    random.seed(args.seed)\n",
    "\n",
    "    coco = None\n",
    "    coco_count = 0\n",
    "    for in_json_tree in in_json_tree_list:\n",
    "        coco = merge_datasets(coco, load_json_tree(in_json_tree))\n",
    "        coco_count += 1\n",
    "    for in_json_file in in_json_file_list:\n",
    "        coco = merge_datasets(coco, load_json_file(in_json_file))\n",
    "        coco_count += 1\n",
    "\n",
    "    if coco is None:\n",
    "        raise ValueError(f'Not found base dataset, please specify either of: '\n",
    "                         '--in_json_tree / --in_json_file (multiple arguments allowed)')\n",
    "    if coco_count > 1:\n",
    "        logger.info(f'Total loaded json dataset: {coco.to_full_str()}')\n",
    "\n",
    "    coco_crop = None\n",
    "    coco_crop_count = 0\n",
    "    for in_crop_tree in in_crop_tree_list:\n",
    "        coco_crop = merge_datasets(coco_crop, load_crop_tree(in_crop_tree, coco))\n",
    "        coco_crop_count += 1\n",
    "    if coco_crop is not None:\n",
    "        if coco_crop_count > 1:\n",
    "            logger.info(f'Total loaded crop-tree dataset: {coco_crop.to_full_str()}')\n",
    "        logger.info('Using coco_crop dataset only.')\n",
    "        coco = coco_crop\n",
    "\n",
    "    if drop_invalid_elements:\n",
    "        coco = remove_invalid_elements(coco)\n",
    "        logger.info(f'After removing invalid elements: {coco.to_full_str()}')\n",
    "\n",
    "    if max_crops_per_class:\n",
    "        logger.info(f'Cutting off crops up to {max_crops_per_class} per class, random seed={seed}')\n",
    "        coco = cut_annotations_per_category(coco, max_crops_per_class)\n",
    "        logger.info(f'After cutting off: {coco.to_full_str()}')\n",
    "\n",
    "    logger.info(f'[.] Result dataset: {coco.to_full_str()}')\n",
    "    details = ''\n",
    "    if out_format is not None:\n",
    "        assert out_path\n",
    "        dump_kwargs = dict(skip_nulls=True, overwrite=overwrite, indent=indent)\n",
    "        if out_format == 'json_file':\n",
    "            dump_fun = dump_json_file\n",
    "        elif out_format == 'json_tree':\n",
    "            dump_fun = dump_json_tree\n",
    "        elif out_format == 'crop_tree':\n",
    "            dump_fun = dump_crop_tree\n",
    "            dump_kwargs['num_processes'] = dump_crop_tree_num_processes\n",
    "        else:\n",
    "            raise ValueError(out_format)\n",
    "        dump_fun(coco, out_path, **dump_kwargs)\n",
    "        if out_path.is_dir():\n",
    "            details = f': {[p.name for p in out_path.iterdir()]}'\n",
    "\n",
    "    logger.info(f'[+] Success: {out_format} dumped to {out_path}' + details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test below, you need to do:\n",
    "# $ cd <project root>\n",
    "# $ make build\n",
    "# $ pip install -e .\n",
    "# reload current notebook kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Arguments: Namespace(debug=False, in_crop_tree=[], in_json_file=[PosixPath('../examples/coco_chunk/json_file/instances_train2017_chunk3x2.json')], in_json_tree=[], indent=4, max_crops_per_class=None, out_format='json_tree', out_path=PosixPath('/tmp/cococo/json_tree'), overwrite=True, seed=42)\n",
      "INFO: Loading json_file from: ../examples/coco_chunk/json_file/instances_train2017_chunk3x2.json\n",
      "INFO:   json file loaded: elapsed 0:00:00.000281\n",
      "INFO:   dataset constructed: elapsed 0:00:00.003357\n",
      "INFO: Loaded json_file: elapsed 0:00:00.003739: CocoObjectDetectionDataset(images=6, licenses=8, annotations=6, categories=3)\n",
      "INFO: Dumping json_tree to dir: /tmp/cococo/json_tree\n",
      "INFO: Dataset written to /tmp/cococo/json_tree: elapsed 0:00:00.001547\n",
      "INFO: [+] Success: json_tree dumped to /tmp/cococo/json_tree: ['info.json', 'info', 'categories', 'annotations', 'licenses', 'images']\n"
     ]
    }
   ],
   "source": [
    "# json_file -> json_tree\n",
    "\n",
    "! rm -rf /tmp/cococo/json_tree\n",
    "! cocorepr \\\n",
    "    --in_json_file ../examples/coco_chunk/json_file/instances_train2017_chunk3x2.json \\\n",
    "    --out_path /tmp/cococo/json_tree \\\n",
    "    --out_format json_tree \\\n",
    "    --overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Arguments: Namespace(debug=False, in_crop_tree=[], in_json_file=[PosixPath('../examples/coco_chunk/json_file/instances_train2017_chunk3x2.json')], in_json_tree=[], indent=4, max_crops_per_class=1, out_format='json_tree', out_path=PosixPath('/tmp/cococo/json_tree'), overwrite=True, seed=42)\n",
      "INFO: Loading json_file from: ../examples/coco_chunk/json_file/instances_train2017_chunk3x2.json\n",
      "INFO: Loaded from json_file: CocoObjectDetectionDataset(images=6, licenses=8, annotations=6, categories=3)\n",
      "INFO: Cutting off crops up to 1 per class, random seed=42\n",
      "INFO: After cutting off: CocoObjectDetectionDataset(images=3, licenses=8, annotations=3, categories=3)\n",
      "INFO: Dumping json_tree to dir: /tmp/cococo/json_tree\n",
      "INFO: [+] Success: json_tree dumped to /tmp/cococo/json_tree: ['info.json', 'info', 'categories', 'annotations', 'licenses', 'images']\n"
     ]
    }
   ],
   "source": [
    "# json_file -> json_tree (same but with --max_crops_per_class)\n",
    "\n",
    "! rm -rf /tmp/cococo/json_tree\n",
    "! cocorepr \\\n",
    "    --in_json_file ../examples/coco_chunk/json_file/instances_train2017_chunk3x2.json \\\n",
    "    --out_path /tmp/cococo/json_tree \\\n",
    "    --out_format json_tree \\\n",
    "    --overwrite \\\n",
    "    --max_crops_per_class=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Arguments: Namespace(debug=False, in_crop_tree=[], in_json_file=[], in_json_tree=[PosixPath('../examples/coco_chunk/json_tree')], indent=None, max_crops_per_class=None, out_format='json_file', out_path=PosixPath('/tmp/cococo/json_file/annotations.json'), overwrite=False, seed=42)\n",
      "INFO: Loading json_tree from dir: ../examples/coco_chunk/json_tree\n",
      "INFO: Loaded from json_tree: CocoObjectDetectionDataset(images=6, licenses=8, annotations=6, categories=3)\n",
      "INFO: Writing dataset CocoObjectDetectionDataset(images=6, licenses=8, annotations=6, categories=3) to json-file: /tmp/cococo/json_file/annotations.json\n",
      "INFO: [+] Success: json_file dumped to /tmp/cococo/json_file/annotations.json\n"
     ]
    }
   ],
   "source": [
    "# json_tree -> json_file\n",
    "\n",
    "! rm -rf /tmp/cococo/json_file\n",
    "! cocorepr \\\n",
    "    --in_json_tree ../examples/coco_chunk/json_tree \\\n",
    "    --out_path /tmp/cococo/json_file/annotations.json \\\n",
    "    --out_format json_file \\\n",
    "    --indent=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Arguments: Namespace(debug=False, in_crop_tree=[], in_json_file=[PosixPath('../examples/coco_chunk/json_file/instances_train2017_chunk3x2.json')], in_json_tree=[], indent=4, max_crops_per_class=None, out_format='crop_tree', out_path=PosixPath('/tmp/cococo/crop_tree'), overwrite=True, seed=42)\n",
      "INFO: Loading json_file from: ../examples/coco_chunk/json_file/instances_train2017_chunk3x2.json\n",
      "INFO: Loaded from json_file: CocoObjectDetectionDataset(images=6, licenses=8, annotations=6, categories=3)\n",
      "INFO: Dumping crop_tree to dir: /tmp/cococo/crop_tree\n",
      "Processing images: 100%|██████████████████████████| 6/6 [00:04<00:00,  1.49it/s]\n",
      "INFO: [+] Success: crop_tree dumped to /tmp/cococo/crop_tree: ['crops', 'images']\n"
     ]
    }
   ],
   "source": [
    "# json_file -> crop_tree\n",
    "\n",
    "! rm -rf /tmp/cococo/crop_tree\n",
    "! cocorepr \\\n",
    "    --in_json_file ../examples/coco_chunk/json_file/instances_train2017_chunk3x2.json \\\n",
    "    --out_path /tmp/cococo/crop_tree \\\n",
    "    --out_format crop_tree \\\n",
    "    --overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bicycle--2'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats = !ls /tmp/cococo/crop_tree/crops\n",
    "cat = cats[0]\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify crop_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'124710.png'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crops = !ls /tmp/cococo/crop_tree/crops/{cat}\n",
    "deleted_crop = crops[0]\n",
    "deleted_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124710.png  124713.png\n",
      "124713.png\n"
     ]
    }
   ],
   "source": [
    "! ls /tmp/cococo/crop_tree/crops/{cat}\n",
    "! rm /tmp/cococo/crop_tree/crops/{cat}/{deleted_crop}\n",
    "! ls /tmp/cococo/crop_tree/crops/{cat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Arguments: Namespace(debug=False, in_crop_tree=PosixPath('/tmp/cococo/crop_tree'), in_json_files=[PosixPath('../examples/coco_chunk/json_file/instances_train2017_chunk3x2.json')], in_json_trees=[], indent=4, out_format='json_tree', out_path=PosixPath('/tmp/cococo/json_tree_2'), overwrite=False)\n",
      "INFO: Loading json file from file: ../examples/coco_chunk/json_file/instances_train2017_chunk3x2.json\n",
      "INFO: Loaded: images=6, annotations=6, categories=3\n",
      "INFO: Loading blob list from dir: /tmp/cococo/crop_tree\n",
      "INFO: Loaded crop tree: len(annotations)=5 len(images)=5 len(categories)=3\n",
      "INFO: Dumping json tree to dir: /tmp/cococo/json_tree_2\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ay/.pyenv/versions/3.7.6/bin/cocorepr\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('cocorepr', 'console_scripts', 'cocorepr')())\n",
      "  File \"/plain/github/nm/cocorepr/cocorepr/main.py\", line 81, in main\n",
      "    dump_fun(coco, out_path, skip_nulls=True, overwrite=overwrite, indent=indent)\n",
      "  File \"/plain/github/nm/cocorepr/cocorepr/json_tree.py\", line 78, in dump_json_tree\n",
      "    raise ValueError(f\"Destination json tree dir already exists: {target_dir}\")\n",
      "ValueError: Destination json tree dir already exists: /tmp/cococo/json_tree_2\n",
      "[+] File successfully not exists\n"
     ]
    }
   ],
   "source": [
    "# json_file + crop_tree (modified) -> json_tree\n",
    "\n",
    "! rm -rf /tmp/json_tree_2\n",
    "! cocorepr \\\n",
    "    --in_json_file ../examples/coco_chunk/json_file/instances_train2017_chunk3x2.json \\\n",
    "    --in_crop_tree /tmp/cococo/crop_tree \\\n",
    "    --out_path /tmp/cococo/json_tree_2 \\\n",
    "    --out_format json_tree\n",
    "\n",
    "! [ ! -f {TMP2}/annotations/{deleted_crop} ] && echo \"[+] File successfully not exists\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Arguments: Namespace(debug=False, in_crop_tree=PosixPath('/tmp/cococo/crop_tree'), in_json_files=[], in_json_trees=[PosixPath('/tmp/cococo/json_tree_2')], indent=4, out_format='crop_tree', out_path=PosixPath('/tmp/cococo/crop_tree_2'), overwrite=False)\n",
      "INFO: Loading json tree from dir: /tmp/cococo/json_tree_2\n",
      "INFO: Loading blob list from dir: /tmp/cococo/crop_tree\n",
      "INFO: Loaded crop tree: len(annotations)=5 len(images)=5 len(categories)=3\n",
      "INFO: Dumping crop tree to dir: /tmp/cococo/crop_tree_2\n",
      "Processing images: 100%|██████████████████████████| 5/5 [00:04<00:00,  1.20it/s]\n",
      "INFO: [+] Success: crop_tree dumped to /tmp/cococo/crop_tree_2: ['crops', 'images']\n",
      "crops\n"
     ]
    }
   ],
   "source": [
    "# json_tree + crop_tree -> crop_tree\n",
    "\n",
    "! rm -rf /tmp/cococo/crop_tree_2\n",
    "! cocorepr \\\n",
    "    --in_json_tree /tmp/cococo/json_tree_2 \\\n",
    "    --in_crop_tree /tmp/cococo/crop_tree \\\n",
    "    --out_path /tmp/cococo/crop_tree_2 \\\n",
    "    --out_format crop_tree\n",
    "! ls /tmp/cococo/crop_tree_2 | grep crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Arguments: Namespace(debug=False, in_crop_tree=PosixPath('/tmp/cococo/crop_tree'), in_json_files=[], in_json_trees=[PosixPath('/tmp/cococo/json_tree_2')], indent=4, out_format='json_file', out_path=PosixPath('/tmp/cococo/json_file_2/annotations.json'), overwrite=False)\n",
      "INFO: Loading json tree from dir: /tmp/cococo/json_tree_2\n",
      "INFO: Loading blob list from dir: /tmp/cococo/crop_tree\n",
      "INFO: Loaded crop tree: len(annotations)=5 len(images)=5 len(categories)=3\n",
      "INFO: Dumping json file to file: /tmp/cococo/json_file_2/annotations.json\n",
      "INFO: Writing dataset to json file: /tmp/cococo/json_file_2/annotations.json\n",
      "INFO: [+] Success: json_file dumped to /tmp/cococo/json_file_2/annotations.json\n",
      "/tmp/cococo/json_file_2/annotations.json\n"
     ]
    }
   ],
   "source": [
    "# json_tree + crop_tree -> json_file\n",
    "\n",
    "! rm -rf /tmp/cococo/json_file_2\n",
    "! cocorepr \\\n",
    "    --in_json_tree /tmp/cococo/json_tree_2 \\\n",
    "    --in_crop_tree /tmp/cococo/crop_tree \\\n",
    "    --out_path /tmp/cococo/json_file_2/annotations.json \\\n",
    "    --out_format json_file\n",
    "\n",
    "! ls /tmp/cococo/json_file_2/annotations.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Arguments: Namespace(debug=False, in_crop_tree=None, in_json_files=[PosixPath('/tmp/cococo/json_file/annotations.json')], in_json_trees=[PosixPath('/tmp/cococo/json_tree_2')], indent=4, out_format='json_file', out_path=PosixPath('/tmp/cococo/json_file_3/annotations.json'), overwrite=True)\n",
      "INFO: Loading json tree from dir: /tmp/cococo/json_tree_2\n",
      "INFO: Loading json file from file: /tmp/cococo/json_file/annotations.json\n",
      "INFO: Loaded: images=6, annotations=6, categories=3\n",
      "INFO: Dumping json file to file: /tmp/cococo/json_file_3/annotations.json\n",
      "INFO: Writing dataset to json file: /tmp/cococo/json_file_3/annotations.json\n",
      "INFO: [+] Success: json_file dumped to /tmp/cococo/json_file_3/annotations.json\n"
     ]
    }
   ],
   "source": [
    "# json_tree + json_file + crop_tree -> json_tree\n",
    "\n",
    "! rm -rf /tmp/cococo/json_file_3/\n",
    "! cocorepr \\\n",
    "    --in_json_tree /tmp/cococo/json_tree_2 \\\n",
    "    --in_json_file /tmp/cococo/json_file/annotations.json \\\n",
    "    --out_path /tmp/cococo/json_file_3/annotations.json \\\n",
    "    --out_format json_file \\\n",
    "    --overwrite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('cocorepr': conda)",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
